{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0cc6c7cb-0245-46a2-aabc-3dd9f1b4b086",
      "metadata": {
        "id": "0cc6c7cb-0245-46a2-aabc-3dd9f1b4b086"
      },
      "source": [
        "# Homework: Implementing a RAG Example with Ollama and Mistral LLM\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this homework, you will be working on a practical application of the DataStax RAGStack. The goal is to modify this Jupyter Notebook that currently leverages OpenAI's LLM (Large Language Models) for a RAG example. Your task is to adapt this notebook to use Ollama running Mistral LLM, as the backbone for the RAG implementation.\n",
        "\n",
        "## Why Ollama?\n",
        "\n",
        "Ollama offers the option to run a LLM on a local machine. Self-managed LLMs are especially of interest for Customers using Cassandra or DSE on-prem and in internet-restricted environments, and for those using Cassandra, DSE and Astra DB who are cautious about sending sensitive data to cloud-based LLM services due to privacy concerns and cost considerations. Ollama enables local execution of Large Language Models, providing a private solution. This is particularly beneficial for demonstrations and aligns with the requirements of businesses handling critical data, ensuring it remains within their controlled environment.\n",
        "\n",
        "For those seeking self-managed LLMs, alternatives like Mistral are available, offering performance comparable to OpenAI's models. Interested parties are encouraged to [review the Mistral documentation](https://huggingface.co/docs/transformers/main/en/model_doc/mistral). Mistral is designed for easy installation and can be efficiently hosted on the robust computing resources available in customer data centers.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "1. **Understand the Current Implementation**: Begin by familiarizing yourself with the existing Jupyter Notebook. It uses DataStax's RAGStack, integrating Astra DB as a vector store, and employs an OpenAI LLM for generating responses.\n",
        "\n",
        "2. **Transition to Ollama and Mistral LLM**: Your primary task is to modify the code in the notebook to replace the OpenAI LLM with Ollama running Mistral LLM. This will involve understanding the differences between the two models and adapting the API calls and data handling accordingly.\n",
        "\n",
        "3. **Test and Validate**: Keep in mind you run notebook and ollama on your local machine. After implementing the changes, test the notebook to ensure that it functions correctly with the new LLM.\n",
        "\n",
        "## Resources\n",
        "\n",
        "- **Ollama Documentation**: [How to install Ollama](https://ollama.com/download) and [How to run Mistral LLM powered by Ollama](https://ollama.com/library/mistral/tags)\n",
        "\n",
        "## Submission Guidelines\n",
        "\n",
        "- Complete the task in the provided Jupyter Notebook.\n",
        "- Ensure all code cells are well-documented.\n",
        "- Submit the final notebook along with a brief report summarizing your approach, key challenges, and solutions.\n",
        "\n",
        "Good luck, and feel free to reach out if you have any questions or need further clarifications!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4e5e9d7-37bd-474b-9c75-f3a82daf41c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4e5e9d7-37bd-474b-9c75-f3a82daf41c0",
        "outputId": "38d08b68-d6c4-4eae-9e41-943c71815fab",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragstack-ai\n",
            "  Downloading ragstack_ai-0.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting astrapy<0.8.0,>=0.7.0 (from ragstack-ai)\n",
            "  Downloading astrapy-0.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting cassio<0.2.0,>=0.1.3 (from ragstack-ai)\n",
            "  Using cached cassio-0.1.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting langchain==0.1.12 (from ragstack-ai)\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-astradb==0.1.0 (from ragstack-ai)\n",
            "  Downloading langchain_astradb-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-community==0.0.28 (from ragstack-ai)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting langchain-core==0.1.31 (from ragstack-ai)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langchain-openai==0.0.8 (from ragstack-ai)\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index==0.9.48 (from llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached llama_index-0.9.48-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting llama-parse==0.1.4 (from ragstack-ai)\n",
            "  Using cached llama_parse-0.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting unstructured==0.12.5 (from ragstack-ai)\n",
            "  Downloading unstructured-0.12.5-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading langsmith-0.1.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy<2,>=1 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
            "Collecting pydantic<3,>=1 (from langchain==0.1.12->ragstack-ai)\n",
            "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.12->ragstack-ai)\n",
            "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting anyio<5,>=3 (from langchain-core==0.1.31->ragstack-ai)\n",
            "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core==0.1.31->ragstack-ai)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai==0.0.8->ragstack-ai)\n",
            "  Downloading openai-1.14.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.0.8->ragstack-ai)\n",
            "  Using cached tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Downloading fsspec-2024.3.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai) (1.6.0)\n",
            "Collecting networkx>=3.0 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting nltk<4.0.0,>=3.8.1 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pandas (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Collecting typing-extensions>=4.5.0 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting chardet (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting filetype (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting lxml (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached lxml-5.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
            "Collecting tabulate (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting beautifulsoup4 (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting emoji (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached emoji-2.10.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting python-iso639 (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
            "Collecting rapidfuzz (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading rapidfuzz-3.6.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
            "Collecting backoff (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting wrapt (from unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
            "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "Collecting tqdm (from sentence-transformers)\n",
            "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Using cached torch-2.2.1-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Using cached scikit_learn-1.4.1.post1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Using cached scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\n",
            "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting Pillow (from sentence-transformers)\n",
            "  Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
            "Collecting deprecation<2.2.0,>=2.1.0 (from astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting toml<0.11.0,>=0.10.2 (from astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting cassandra-driver>=3.28.0 (from cassio<0.2.0,>=0.1.3->ragstack-ai)\n",
            "  Using cached cassandra_driver-3.29.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
            "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.32.0->sentence-transformers)\n",
            "  Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.32.0->sentence-transformers)\n",
            "  Using cached tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence-transformers)\n",
            "  Using cached safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
            "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3->langchain-core==0.1.31->ragstack-ai)\n",
            "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core==0.1.31->ragstack-ai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver>=3.28.0->cassio<0.2.0,>=0.1.3->ragstack-ai)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting certifi (from httpx->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting httpcore==1.* (from httpx->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting h2<5,>=3 (from httpx[http2]<1,>=0.25.2->astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Using cached h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.12->ragstack-ai)\n",
            "  Downloading orjson-3.9.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click (from nltk<4.0.0,>=3.8.1->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.10.0->langchain-openai==0.0.8->ragstack-ai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached pydantic_core-2.16.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.1.12->ragstack-ai)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pypdf>=4.0 (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.16.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai) (1.16.0)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured==0.12.5->ragstack-ai)\n",
            "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->llama-index==0.9.48->llama-index[langchain]==0.9.48->ragstack-ai)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=6.0->unstructured-client>=0.15.1->unstructured==0.12.5->ragstack-ai)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Using cached hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<0.8.0,>=0.7.0->ragstack-ai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading ragstack_ai-0.10.0-py3-none-any.whl (4.3 kB)\n",
            "Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_astradb-0.1.0-py3-none-any.whl (25 kB)\n",
            "Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Using cached llama_index-0.9.48-py3-none-any.whl (15.9 MB)\n",
            "Using cached llama_parse-0.1.4-py3-none-any.whl (4.4 kB)\n",
            "Downloading unstructured-0.12.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "Downloading astrapy-0.7.7-py3-none-any.whl (32 kB)\n",
            "Using cached cassio-0.1.5-py3-none-any.whl (41 kB)\n",
            "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
            "Using cached torch-2.2.1-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
            "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
            "Using cached scikit_learn-1.4.1.post1-cp311-cp311-macosx_12_0_arm64.whl (10.4 MB)\n",
            "Using cached scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl (31.4 MB)\n",
            "Using cached aiohttp-3.9.3-cp311-cp311-macosx_11_0_arm64.whl (387 kB)\n",
            "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "Using cached cassandra_driver-3.29.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
            "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading langsmith-0.1.27-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "Downloading openai-1.14.1-py3-none-any.whl (257 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-23.2-py3-none-any.whl (53 kB)\n",
            "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic_core-2.16.3-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
            "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
            "Using cached regex-2023.12.25-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Using cached safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl (393 kB)\n",
            "Downloading SQLAlchemy-2.0.28-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Downloading tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tokenizers-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
            "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
            "Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Using cached emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Using cached lxml-5.1.0-cp311-cp311-macosx_11_0_arm64.whl (4.5 MB)\n",
            "Using cached pandas-2.2.1-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
            "Using cached python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading rapidfuzz-3.6.2-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
            "Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
            "Using cached geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
            "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
            "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading orjson-3.9.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: pytz, mpmath, filetype, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, toml, threadpoolctl, tenacity, tabulate, sympy, soupsieve, sniffio, safetensors, regex, rapidfuzz, PyYAML, python-magic, python-iso639, pypdf, Pillow, packaging, orjson, ordered-set, numpy, networkx, mypy-extensions, multidict, MarkupSafe, lxml, langdetect, jsonpointer, jsonpath-python, joblib, idna, hyperframe, hpack, h11, greenlet, fsspec, frozenlist, filelock, emoji, distro, click, charset-normalizer, chardet, certifi, backoff, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, scipy, requests, pydantic-core, pandas, nltk, marshmallow, jsonpatch, jinja2, httpcore, h2, geomet, deprecation, deprecated, deepdiff, beautifulsoup4, anyio, aiosignal, torch, tiktoken, scikit-learn, pydantic, huggingface-hub, httpx, dataclasses-json, cassandra-driver, aiohttp, unstructured-client, tokenizers, openai, langsmith, cassio, unstructured, transformers, llama-index, langchain-core, astrapy, sentence-transformers, llama-parse, langchain-text-splitters, langchain-openai, langchain-community, langchain-astradb, langchain, ragstack-ai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed MarkupSafe-2.1.5 Pillow-10.2.0 PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 astrapy-0.7.7 attrs-23.2.0 backoff-2.2.1 beautifulsoup4-4.12.3 cassandra-driver-3.29.0 cassio-0.1.5 certifi-2024.2.2 chardet-5.2.0 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.4 deepdiff-6.7.1 deprecated-1.2.14 deprecation-2.1.0 dirtyjson-1.0.8 distro-1.9.0 emoji-2.10.1 filelock-3.13.1 filetype-1.2.0 frozenlist-1.4.1 fsspec-2024.3.0 geomet-0.2.1.post1 greenlet-3.0.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.4 httpx-0.27.0 huggingface-hub-0.21.4 hyperframe-6.0.1 idna-3.6 jinja2-3.1.3 joblib-1.3.2 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.12 langchain-astradb-0.1.0 langchain-community-0.0.28 langchain-core-0.1.31 langchain-openai-0.0.8 langchain-text-splitters-0.0.1 langdetect-1.0.9 langsmith-0.1.27 llama-index-0.9.48 llama-parse-0.1.4 lxml-5.1.0 marshmallow-3.21.1 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 openai-1.14.1 ordered-set-4.1.0 orjson-3.9.15 packaging-23.2 pandas-2.2.1 pydantic-2.6.4 pydantic-core-2.16.3 pypdf-4.1.0 python-iso639-2024.2.7 python-magic-0.4.27 pytz-2024.1 ragstack-ai-0.10.0 rapidfuzz-3.6.2 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 scikit-learn-1.4.1.post1 scipy-1.12.0 sentence-transformers-2.5.1 sniffio-1.3.1 soupsieve-2.5 sympy-1.12 tabulate-0.9.0 tenacity-8.2.3 threadpoolctl-3.3.0 tiktoken-0.6.0 tokenizers-0.15.2 toml-0.10.2 torch-2.2.1 tqdm-4.66.2 transformers-4.38.2 typing-extensions-4.10.0 typing-inspect-0.9.0 tzdata-2024.1 unstructured-0.12.5 unstructured-client-0.22.0 urllib3-2.2.1 wrapt-1.16.0 yarl-1.9.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ragstack-ai sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a4f99fe7-000b-4dcb-a89b-b4e784daed0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4f99fe7-000b-4dcb-a89b-b4e784daed0f",
        "outputId": "a2839d71-0373-43ba-e5c7-800ba61fb6b5"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "ASTRA_DB_API_ENDPOINT = input(\"Please provide your ASTRA_DB_API_ENDPOINT: \")\n",
        "ASTRA_DB_APPLICATION_TOKEN = getpass.getpass(\"Enter your ASTRA_DB_APPLICATION_TOKEN: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b8e3ddd0-5078-4398-8ef2-3465b7770dcd",
      "metadata": {
        "id": "b8e3ddd0-5078-4398-8ef2-3465b7770dcd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "61622a71-de5f-44e7-bc06-ae4555530304",
      "metadata": {
        "id": "61622a71-de5f-44e7-bc06-ae4555530304"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "response = requests.get('https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt')\n",
        "text = response.text\n",
        "\n",
        "f = open('essay.txt', 'w')\n",
        "f.write(text)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9g96Kbz40_cK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g96Kbz40_cK",
        "outputId": "e6ac2033-b2f0-43aa-e934-9baf8ecd3f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-0.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.27 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-mistralai) (0.1.31)\n",
            "Collecting mistralai<0.2,>=0.1 (from langchain-mistralai)\n",
            "  Downloading mistralai-0.1.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-mistralai) (0.15.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (4.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (0.1.27)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (8.2.3)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Using cached httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.10 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from mistralai<0.2,>=0.1->langchain-mistralai) (3.9.15)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.2.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from mistralai<0.2,>=0.1->langchain-mistralai) (2.2.1)\n",
            "Collecting pyarrow<16.0.0,>=15.0.0 (from mistralai<0.2,>=0.1->langchain-mistralai)\n",
            "  Downloading pyarrow-15.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (0.21.4)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->mistralai<0.2,>=0.1->langchain-mistralai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from httpx<0.26.0,>=0.25.2->mistralai<0.2,>=0.1->langchain-mistralai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai<0.2,>=0.1->langchain-mistralai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (2024.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (4.10.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (2.4)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.27->langchain-mistralai) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/juan.abello/Documents/Datastax/astradb-examples/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.0->mistralai<0.2,>=0.1->langchain-mistralai) (1.16.0)\n",
            "Downloading langchain_mistralai-0.0.5-py3-none-any.whl (10 kB)\n",
            "Downloading mistralai-0.1.6-py3-none-any.whl (15 kB)\n",
            "Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "Downloading pyarrow-15.0.1-cp311-cp311-macosx_11_0_arm64.whl (24.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, httpx, mistralai, langchain-mistralai\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "Successfully installed httpx-0.25.2 langchain-mistralai-0.0.5 mistralai-0.1.6 pyarrow-15.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "079ea2c2-b256-4942-aec8-cbf6b69d5697",
      "metadata": {
        "id": "079ea2c2-b256-4942-aec8-cbf6b69d5697"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.chat_models import ChatOllama # Replace ChatMistralAI or ChatOpenAI with ChatMistral\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import AstraDB\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bb2b6310-7b61-4cd1-b329-b8e52275cca5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb2b6310-7b61-4cd1-b329-b8e52275cca5",
        "outputId": "039c22c5-a90a-4a89-fa32-948ff7cf78bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The two main things the author worked on before college were learning piano and programming.\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "loader = TextLoader(\"essay.txt\")\n",
        "docs = loader.load()\n",
        "# Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)\n",
        "# Define the embedding model\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "#vector = load_vector_store()\n",
        "#vector = AstraDB.from_documents(documents, embeddings,collection_name=\"openai_demo\", api_endpoint=ASTRA_DB_API_ENDPOINT, token=ASTRA_DB_APPLICATION_TOKEN)\n",
        "vector = AstraDB.from_documents(documents, embeddings, collection_name=\"mistral_demo\", api_endpoint=ASTRA_DB_API_ENDPOINT, token=ASTRA_DB_APPLICATION_TOKEN)\n",
        "# Define a retriever interface\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "#Use Ollama LLM with Mistral model\n",
        "model = ChatOllama(model=\"mistral\")\n",
        "# Define prompt template\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\"\"\")\n",
        "\n",
        "# Create a retrieval chain to answer questions\n",
        "document_chain = create_stuff_documents_chain(model, prompt)\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
        "response = retrieval_chain.invoke({\"input\": \"What were the two main things the author worked on before college?\"})\n",
        "print(response[\"answer\"])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
